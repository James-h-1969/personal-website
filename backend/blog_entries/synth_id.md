# Google DeepMinds "SynthId""
### Why you didn't rob that Bank
You get a knock on the door from the police. 

They show you a video of someone getting shot in the middle of the street. Broad daylight.
The attacker is wearing a balaclava, but while pandamonium breaks loose on the street, they 
turn to the camera (presumingly an iphone of some random) and take it off their head. To your 
shock, you see your own face. 

Impossible - you have been at home all day! Although this is an extreme example, as text to image 
models get better, this is a genuine situation that could happen in the next 5-10 years as the models 
become more realistic. All photos and videos used as evidence in court are suddenly moot, rendered obsolete
as we suddenly have to ask - are these fake or not?

Luckily, Google and specifically the team at DeepMind have already thought of this. They have developed 
a digital fingerprint (SynthId), that is impossible to observe to the naked eye. It allows us to answer the 
question of whether the image is fake or not, no matter if the image has been altered, cropped or skewed. 

So don't worry, you won't be going to prison yet. 

### For the nerds 
So how does it work? 

The implementation of the SynthId has been made for text, image/video and audio. Currently, only the text based 
model has been [Open Sourced](https://github.com/google-deepmind/synthid-text) so it will be discussed today.

Currently there are three ways to watermark text - generative watermarking, edit-based wate

https://www.nature.com/articles/s41586-024-08025-4
https://deepmind.google/science/synthid/



### Why you didn't rob that Bank
You get a knock on the door from the police. 

They show you a video of someone getting shot in the middle of the street. Broad daylight.
The attacker is wearing a balaclava, but while pandamonium breaks loose on the street, they 
turn to the camera (presumingly an iphone of some random) and take it off their head. To your 
shock, you see your own face. 

Impossible - you have been at home all day! Although this is an extreme example, as text to image 
models get better, this is a genuine situation that could happen in the next 5-10 years as the models 
become more realistic. All photos and videos used as evidence in court are suddenly moot, rendered obsolete
as we suddenly have to ask - are these fake or not?

Luckily, Google and specifically the team at DeepMind have already thought of this. They have developed 
a digital fingerprint (SynthId), that is impossible to observe to the naked eye. It allows us to answer the 
question of whether the image is fake or not, no matter if the image has been altered, cropped or skewed. 

So don't worry, you won't be going to prison yet. 

### For the nerds 
So how does it work? 

The implementation of the SynthId has been made for text, image/video and audio. Currently, only the text based 
model has been [Open Sourced](https://github.com/google-deepmind/synthid-text) so it will be discussed today.

Currently there are three ways to watermark text - generative watermarking, edit-based wate

https://www.nature.com/articles/s41586-024-08025-4
https://deepmind.google/science/synthid/



